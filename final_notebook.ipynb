{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3768119b-0de0-40e0-b359-92ed68344047",
   "metadata": {},
   "source": [
    "This notebook does not prep the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a587fe03-f297-4dc7-bd0a-89573bba46b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import itertools\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras_tuner\n",
    "from keras_tuner import RandomSearch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c75128bf-a270-4863-a201-b634f1194dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preferences\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93012a98-c3f5-4e8a-8369-e6f7c57f6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path variables\n",
    "train_path = \"data/train/\"\n",
    "val_path = \"data/val/\"\n",
    "test_path = \"data/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c413d5ed-c2f0-4f1f-936a-e71097e9ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = [train_path, val_path, test_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af6d8fe5-5883-43b2-a833-9ae12b6624cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be5edfba-2de7-4a37-8f9f-a0efa2076794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5097 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(directory=train_path,\n",
    "                                              target_size=(256,256),\n",
    "                                              batch_size=16,\n",
    "                                              color_mode=\"grayscale\",\n",
    "                                              classes=[\"NORMAL\", \"viral_pneumonia\", \"bacterial_pneumonia\"],\n",
    "                                              save_format=\"jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba090c0-a5ad-4cca-9205-35ad7d1aec56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 135 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = datagen.flow_from_directory(directory=val_path,\n",
    "                                            target_size=(256,256),\n",
    "                                            batch_size=16,\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            classes=[\"NORMAL\", \"viral_pneumonia\", \"bacterial_pneumonia\"],\n",
    "                                            save_format=\"jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49a9c183-e3ac-437b-b67e-2ceb434dae24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen.flow_from_directory(directory=test_path,\n",
    "                                             target_size=(256,256),\n",
    "                                             batch_size=16,\n",
    "                                             color_mode=\"grayscale\",\n",
    "                                             classes=[\"NORMAL\", \"viral_pneumonia\", \"bacterial_pneumonia\"],\n",
    "                                             save_format=\"jpeg\",\n",
    "                                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cce71a7b-4f7d-4c08-9ad0-c1bbfde1cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, labels = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9453870-c71b-4040-9865-74a030054f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    Building a model to optimize hypter parameters.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=hp.Int(\"conv_1_filter\",\n",
    "                                    min_value=16,\n",
    "                                    max_value=256,\n",
    "                                    step=16),\n",
    "                     kernel_size=hp.Choice(\"conv_1_kernel\", values = [3,5]),\n",
    "                     activation=\"relu\",\n",
    "                     input_shape=(256,256,1)))\n",
    "    model.add(MaxPool2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=hp.Int(\"conv_1_filter\",\n",
    "                                    min_value=16,\n",
    "                                    max_value=256,\n",
    "                                    step=16),\n",
    "                     kernel_size=hp.Choice(\"conv_2_kernel\", values = [3,5]),\n",
    "                     activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=hp.Int(\"dense_1_units\",\n",
    "                                 min_value=16,\n",
    "                                 max_value=256,\n",
    "                                 step=16),\n",
    "                    activation=\"relu\"))\n",
    "    model.add(Dense(units=3, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3])),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\", tf.keras.metrics.Recall()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d5beaa4-bc01-4a16-9129-b873f3d43932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 10:40:43.548690: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "tuner_search = RandomSearch(build_model,\n",
    "                            objective=\"val_accuracy\",\n",
    "                            max_trials=5,\n",
    "                            directory=\"output\",\n",
    "                            project_name=\"ChestXrayPneumoniaAccuracy2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282dd42-ea84-470a-8a52-f824af70b4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "96                |96                |conv_1_filter\n",
      "3                 |3                 |conv_1_kernel\n",
      "5                 |5                 |conv_2_kernel\n",
      "144               |144               |dense_1_units\n",
      "0.01              |0.01              |learning_rate\n",
      "\n",
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search(train_generator, epochs=3, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4c9732-b0f8-4001-8a3c-963dbc068283",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner_search.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9630e4-dd87-43d8-9b40-d39fe161eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1440867-b80f-475c-aae1-b5867f05bc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Best Model so far:\n",
    "\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " conv2d (Conv2D)             (None, 254, 254, 32)      320       \n",
    "                                                                 \n",
    " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
    " )                                                               \n",
    "                                                                 \n",
    " conv2d_1 (Conv2D)           (None, 123, 123, 32)      25632     \n",
    "                                                                 \n",
    " max_pooling2d_1 (MaxPooling  (None, 61, 61, 32)       0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " flatten (Flatten)           (None, 119072)            0         \n",
    "                                                                 \n",
    " dense (Dense)               (None, 64)                7620672   \n",
    "                                                                 \n",
    " dense_1 (Dense)             (None, 3)                 195       \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 7,646,819\n",
    "Trainable params: 7,646,819\n",
    "Non-trainable params: 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b091b900-4cad-4fa9-8cc4-655e7910e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_generator, epochs=10, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc6afd2-51f9-4673-9b90-69f93570904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Best model so far:\n",
    "Epoch 1/10\n",
    "160/160 [==============================] - 253s 2s/step - loss: 0.5829 - accuracy: 0.7555 - recall: 0.7181 - val_loss: 0.8309 - val_accuracy: 0.6296 - val_recall: 0.5778\n",
    "Epoch 2/10\n",
    "160/160 [==============================] - 230s 1s/step - loss: 0.5477 - accuracy: 0.7652 - recall: 0.7406 - val_loss: 0.9381 - val_accuracy: 0.6815 - val_recall: 0.6222\n",
    "Epoch 3/10\n",
    "160/160 [==============================] - 208s 1s/step - loss: 0.4409 - accuracy: 0.8115 - recall: 0.7924 - val_loss: 0.7269 - val_accuracy: 0.7333 - val_recall: 0.7111\n",
    "Epoch 4/10\n",
    "160/160 [==============================] - 262s 2s/step - loss: 0.3365 - accuracy: 0.8552 - recall: 0.8468 - val_loss: 0.7431 - val_accuracy: 0.7630 - val_recall: 0.7481\n",
    "Epoch 5/10\n",
    "160/160 [==============================] - 284s 2s/step - loss: 0.2476 - accuracy: 0.8974 - recall: 0.8925 - val_loss: 0.9234 - val_accuracy: 0.7556 - val_recall: 0.7407\n",
    "Epoch 6/10\n",
    "160/160 [==============================] - 219s 1s/step - loss: 0.1834 - accuracy: 0.9247 - recall: 0.9233 - val_loss: 1.0953 - val_accuracy: 0.6963 - val_recall: 0.6963\n",
    "Epoch 7/10\n",
    "160/160 [==============================] - 344s 2s/step - loss: 0.1453 - accuracy: 0.9437 - recall: 0.9429 - val_loss: 1.1727 - val_accuracy: 0.7407 - val_recall: 0.7407\n",
    "Epoch 8/10\n",
    "160/160 [==============================] - 269s 2s/step - loss: 0.0886 - accuracy: 0.9659 - recall: 0.9655 - val_loss: 1.5430 - val_accuracy: 0.7259 - val_recall: 0.7185\n",
    "Epoch 9/10\n",
    "160/160 [==============================] - 203s 1s/step - loss: 0.0777 - accuracy: 0.9733 - recall: 0.9723 - val_loss: 1.7865 - val_accuracy: 0.7185 - val_recall: 0.7185\n",
    "Epoch 10/10\n",
    "160/160 [==============================] - 233s 1s/step - loss: 0.0888 - accuracy: 0.9739 - recall: 0.9735 - val_loss: 1.9146 - val_accuracy: 0.7333 - val_recall: 0.7333\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a563540c-6687-4d29-b733-24e2b5e8cbc4",
   "metadata": {},
   "source": [
    "#Building a CNN\n",
    "model = Sequential([\n",
    "    Conv2D(filters = 32, kernel_size=(3,3), activation=\"relu\", padding=\"same\", input_shape=(256,256,1)),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2),\n",
    "    Conv2D(filters = 64, kernel_size=(3,3), activation=\"relu\", padding=\"same\"),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2),\n",
    "    Conv2D(filters = 128, kernel_size=(3,3), activation=\"relu\", padding=\"same\"),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=3, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb32397-3ecc-47c9-bb54-d9571463e28b",
   "metadata": {},
   "source": [
    "#Compiling the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\", tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb45df6-ca90-4fc0-835e-03ed35bfff9d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model.fit(x=train_generator, validation_data=val_generator, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2ef0c6-a306-48e4-876c-e8596bfa9525",
   "metadata": {},
   "source": [
    "### Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb47bef-9945-4908-a012-3f2cfbbe7f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot function\n",
    "def plotImages(images_arr):\n",
    "    \"\"\"\n",
    "    Plots images in a gird.\n",
    "    \"\"\"\n",
    "    fig, axes, = plt.subplots(1, 10, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fc7fde-d2cc-48d6-9fca-b3805f86ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs, test_labels = next(test_generator)\n",
    "plotImages(test_imgs)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13739bc0-1b8f-4e36-909d-bf47644e5daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=test_generator, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43def967-e3a9-46f1-b8ee-49b0b64b73db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_generator.classes, y_pred=np.argmax(predictions0, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4353396-c445-4a73-9dad-dd12960e7a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix plot function from TensorFlows website\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title=\"Confusion Matrix\", cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    A function to plot results in a confusion matrix.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print(\"Confusion matrix, without normalization\")\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i,j], horizontalalignment=\"center\", color = \"white\" if cm[i,j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee22042-2a0b-496d-b47a-c79590ccb271",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = [\"Normal\",\"viral_pneumonia\", \"bacterial_pneumonia\"]\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3ae9c3-cde3-4f10-9180-9e61e6574eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
